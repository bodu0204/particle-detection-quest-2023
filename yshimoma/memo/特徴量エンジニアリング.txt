
pytorchで公開されている学習済みモデルを利用しても良いのでしょうか？


パーティクルクエスト
・特徴量エンジニアリング
・機械学習・ディープラーニング
・

特徴量エンジニアリング
	特徴量とは、分析対象データの中の、予測の手掛かりとなる変数のこと。
	特徴量の選択によりアルゴリズムの結果が大きく変わる。
	特徴量エンジニアリングは、オリジナルデータから機械学習モデル（AIモデル）に有用な説明変数（特徴量）を作成する作業


	画像データに対する特徴量エンジニアリングを行う際に考慮すべき重要な要素を以下にまとめました。
	ドメインの理解:
		解決しようとする問題（例えば、顔認識、物体検出、医療画像診断など）に特有のドメイン知識を理解することは、
		関連する特徴を特定し、抽出するために非常に重要です。
			どのような特徴量が異物の存在を効果的に示すかを考え、画像解析アルゴリズムの開発に活かします。
			例えば、異物の形状、サイズ、テクスチャ、色の変化などを特定し、これらを機械学習モデルで識別するための
			特徴量として設計することになります。
	データの前処理:
		画像のノイズ除去、正規化、リサイズ、色空間の変換など、画像を分析に適した形式に前処理することが基本です。
	エッジ検出:
		エッジは画像の基本的な特徴であり、物体の境界を特定するのに役立ちます。ソーベル、プリューウィット、
		キャニーなどのエッジ検出フィルタがよく使われます。
	キーポイントとディスクリプタ:
		SIFT、SURF、ORBなどのアルゴリズムを使用して画像からキーポイント（興味深い点）を検出し、
		それぞれのキーポイントに関するディスクリプタ（説明子）を抽出します。
	テクスチャ分析:
		画像内のテクスチャパターンを分析し、局所バイナリパターン（LBP）、グレーレベル共起行列（GLCM）などの
		特徴を抽出します。
	色の特徴量:
		色ヒストグラムや色相、彩度、明度（HSL/HSV）などの色空間に基づいた特徴量を使用することができます。
	形状特徴量:
		物体の輪郭から抽出される形状特徴量は、特定のオブジェクトを認識するのに有用です。
	次元削減:
		主成分分析（PCA）、線形判別分析（LDA）、t-SNEなどを利用して特徴量の次元を削減し、
		計算量を減少させつつも重要な情報を保持します。
	データ拡張:
		過学習を防ぐために画像を回転、反転、クロップするなどしてデータの多様性を増やします。
	深層学習の活用:
		畳み込みニューラルネットワーク（CNN）は、階層的な特徴を自動で学習することができます。
		転移学習を使用して、大きなデータセットで事前に訓練されたモデルの重みを活用することも有効です。


TODO
	画像データを分析
	どの項目が必要でどの項目が不要か考える。
	
	